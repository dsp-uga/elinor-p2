{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from operator import add\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql import SQLContext,Row\n",
    "from operator import add\n",
    "import numpy as np\n",
    "import string\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,NGram\n",
    "\n",
    "#sc = pyspark.SparkContext('local[*]',appName=\"DocClassification\")\n",
    "#sqlc = SQLContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 doc|did|\n",
      "+--------------------+---+\n",
      "|This is something...|  0|\n",
      "|To test something...|  1|\n",
      "|I need to do some...|  2|\n",
      "|This is something...|  3|\n",
      "|To test something...|  4|\n",
      "|I need to do some...|  5|\n",
      "|This is something...|  6|\n",
      "|To test something...|  7|\n",
      "|I need to do some...|  8|\n",
      "|This is something...|  9|\n",
      "|To test something...| 10|\n",
      "|I need to do some...| 11|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize([\"This is something I really want to test.\",\n",
    "                       \"To test something is something I really want to do.\",\n",
    "                       \"I need to do something that I want to do which is to test something.\",\n",
    "                       \"This is something I really want to test.\",\n",
    "                       \"To test something is something I really want to do.\",\n",
    "                       \"I need to do something that I want to do which is to test something.\",\n",
    "                       \"This is something I really want to test.\",\n",
    "                       \"To test something is something I really want to do.\",\n",
    "                       \"I need to do something that I want to do which is to test something.\",\n",
    "                       \"This is something I really want to test.\",\n",
    "                       \"To test something is something I really want to do.\",\n",
    "                       \"I need to do something that I want to do which is to test something.\"])\\\n",
    "            .zipWithIndex()\\\n",
    "            .toDF(['doc','did'])\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+--------------------+\n",
      "|                 doc|did|               words|               grams|\n",
      "+--------------------+---+--------------------+--------------------+\n",
      "|This is something...|  0|[this, is, someth...|[this is, is some...|\n",
      "|To test something...|  1|[to, test, someth...|[to test, test so...|\n",
      "|I need to do some...|  2|[i, need, to, do,...|[i need, need to,...|\n",
      "|This is something...|  3|[this, is, someth...|[this is, is some...|\n",
      "|To test something...|  4|[to, test, someth...|[to test, test so...|\n",
      "|I need to do some...|  5|[i, need, to, do,...|[i need, need to,...|\n",
      "|This is something...|  6|[this, is, someth...|[this is, is some...|\n",
      "|To test something...|  7|[to, test, someth...|[to test, test so...|\n",
      "|I need to do some...|  8|[i, need, to, do,...|[i need, need to,...|\n",
      "|This is something...|  9|[this, is, someth...|[this is, is some...|\n",
      "|To test something...| 10|[to, test, someth...|[to test, test so...|\n",
      "|I need to do some...| 11|[i, need, to, do,...|[i need, need to,...|\n",
      "+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toker = Tokenizer(inputCol = \"doc\",outputCol = \"words\")\n",
    "data = toker.transform(data)\n",
    "grammer = NGram(n=2,inputCol=\"words\",outputCol=\"grams\")\n",
    "data = grammer.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|did|            features|\n",
      "+---+--------------------+\n",
      "|  0|[this, is, someth...|\n",
      "|  1|[to, test, someth...|\n",
      "|  2|[i, need, to, do,...|\n",
      "|  3|[this, is, someth...|\n",
      "|  4|[to, test, someth...|\n",
      "|  5|[i, need, to, do,...|\n",
      "|  6|[this, is, someth...|\n",
      "|  7|[to, test, someth...|\n",
      "|  8|[i, need, to, do,...|\n",
      "|  9|[this, is, someth...|\n",
      "| 10|[to, test, someth...|\n",
      "| 11|[i, need, to, do,...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.rdd.map(lambda x: Row(did=x['did'],features=x['words']+x['grams'])).toDF()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can very easily add the labels onto your DF if you already have them joined in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "|did|            features|         rawFeatures|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|[this, is, someth...|(262144,[14,15889...|\n",
      "|  1|[to, test, someth...|(262144,[14,15889...|\n",
      "|  2|[i, need, to, do,...|(262144,[4249,158...|\n",
      "|  3|[this, is, someth...|(262144,[14,15889...|\n",
      "|  4|[to, test, someth...|(262144,[14,15889...|\n",
      "|  5|[i, need, to, do,...|(262144,[4249,158...|\n",
      "|  6|[this, is, someth...|(262144,[14,15889...|\n",
      "|  7|[to, test, someth...|(262144,[14,15889...|\n",
      "|  8|[i, need, to, do,...|(262144,[4249,158...|\n",
      "|  9|[this, is, someth...|(262144,[14,15889...|\n",
      "| 10|[to, test, someth...|(262144,[14,15889...|\n",
      "| 11|[i, need, to, do,...|(262144,[4249,158...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hasher = HashingTF(inputCol = 'features',outputCol='rawFeatures')\n",
    "data = hasher.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(data.where(data.did==0).select('features').rdd.map(lambda x: x[0]).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
