{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=DocClassification, master=local[*]) created by __init__ at <ipython-input-1-e07a1cb406c3>:14 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e07a1cb406c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorUDT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorIndexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DocClassification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0msqlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MacBot/anaconda/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Users/MacBot/anaconda/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 299\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=DocClassification, master=local[*]) created by __init__ at <ipython-input-1-e07a1cb406c3>:14 "
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from operator import add\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql import SQLContext\n",
    "from operator import add\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n",
    "import string\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "sc = pyspark.SparkContext('local[*]',appName=\"DocClassification\")\n",
    "sqlc = SQLContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'this'), 1), ((0, 'is'), 1), ((0, 'something'), 1), ((0, 'i'), 1), ((0, 'really'), 1), ((0, 'want'), 1), ((0, 'to'), 1), ((0, 'test'), 1), ((1, 'to'), 1), ((1, 'test'), 1), ((1, 'something'), 1), ((1, 'is'), 1), ((1, 'something'), 1), ((1, 'i'), 1), ((1, 'really'), 1), ((1, 'want'), 1), ((1, 'to'), 1), ((1, 'do'), 1), ((2, 'i'), 1), ((2, 'need'), 1), ((2, 'to'), 1), ((2, 'do'), 1), ((2, 'something'), 1), ((2, 'that'), 1), ((2, 'i'), 1), ((2, 'want'), 1), ((2, 'to'), 1), ((2, 'do'), 1), ((2, 'which'), 1), ((2, 'is'), 1), ((2, 'to'), 1), ((2, 'test'), 1), ((2, 'something'), 1)]\n",
      "+---+-----+\n",
      "|did|label|\n",
      "+---+-----+\n",
      "|  0|    1|\n",
      "|  1|    0|\n",
      "|  2|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def swap(x):\n",
    "    return (x[1],x[0])\n",
    "\n",
    "strs = sc.parallelize([\"This is something I really want to test.\",\n",
    "                       \"To test something is something I really want to do.\",\n",
    "                       \"I need to do something that I want to do which is to test something.\"])\n",
    "strs = strs.zipWithIndex()\\\n",
    "            .map(lambda x: swap(x))\\\n",
    "            .flatMapValues(lambda x: x.split())\\\n",
    "            .mapValues(lambda x: x.lower().strip(string.punctuation))\\\n",
    "            .map(lambda x: ((x[0],x[1]),1))\n",
    "\n",
    "labs = sc.parallelize([(0,1),(1,0),(2,1)]).toDF([\"did\",\"label\"])\n",
    "            \n",
    "print(strs.collect())\n",
    "labs.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1), (0, 2, 1), (0, 3, 1), (0, 8, 1), (0, 4, 1), (0, 9, 1), (0, 10, 1), (0, 11, 1), (1, 0, 1), (1, 2, 2), (1, 3, 1), (1, 1, 1), (1, 4, 2), (1, 9, 1), (1, 10, 1), (1, 11, 1), (2, 0, 2), (2, 2, 2), (2, 5, 1), (2, 6, 1), (2, 7, 1), (2, 1, 2), (2, 4, 3), (2, 9, 1), (2, 10, 1), (2, 11, 1)]\n",
      "+---+--------------------+\n",
      "|did|            features|\n",
      "+---+--------------------+\n",
      "|  0|(12,[0,2,3,4,8,9,...|\n",
      "|  1|(12,[0,1,2,3,4,9,...|\n",
      "|  2|(12,[0,1,2,4,5,6,...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sstrs = strs.reduceByKey(add)\\\n",
    "            .map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
    "    \n",
    "vocab = sstrs.keys().distinct().zipWithIndex()\n",
    "\n",
    "sstrs = sstrs.join(vocab).map(lambda x: (x[1][0][0],x[1][1],x[1][0][1]))\n",
    "print(sstrs.sortBy(lambda x: x[0]).collect())\n",
    "\n",
    "sstrs = sstrs.map(lambda x: MatrixEntry(x[0],x[1],x[2]))\n",
    "mat = CoordinateMatrix(sstrs).toIndexedRowMatrix().rows.toDF([\"did\",\"features\"])\n",
    "mat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "|did|            features|label|\n",
      "+---+--------------------+-----+\n",
      "|  0|(12,[0,2,3,4,8,9,...|    1|\n",
      "|  1|(12,[0,1,2,3,4,9,...|    0|\n",
      "|  2|(12,[0,1,2,4,5,6,...|    1|\n",
      "+---+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin = mat.join(labs,['did'])\n",
    "fin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(did=0, features=SparseVector(12, {0: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0}), label=1),\n",
       " Row(did=1, features=SparseVector(12, {0: 1.0, 1: 1.0, 2: 2.0, 3: 1.0, 4: 2.0, 9: 1.0, 10: 1.0, 11: 1.0}), label=0),\n",
       " Row(did=2, features=SparseVector(12, {0: 2.0, 1: 2.0, 2: 2.0, 4: 3.0, 5: 1.0, 6: 1.0, 7: 1.0, 9: 1.0, 10: 1.0, 11: 1.0}), label=1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
