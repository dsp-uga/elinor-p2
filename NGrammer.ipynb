{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hopefully demonstrates the difficulty I ran into. I want to make a generic N-grammer. Here I'm focusing on 2-grams just for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "\n",
    "def getTestPaths(args):\n",
    "    if args==None: return (None,None)\n",
    "    else :\n",
    "        return (args[0],args[1])\n",
    "\n",
    "\n",
    "def swap(tup):\n",
    "    return (tup[1],tup[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    DATA_PATH  = \"data/smaller.txt\"\n",
    "    N          = 2\n",
    "    OUT_PATH   = \"data/NGrams/smaller\" + str(N)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Project0\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to make a list of RDDs that is as big as the size of the n-gram we're looking at. In this case it's just 2. Then I try to push each RDD into the list one at a time, with progressively one-off indices as their keys. In other words, the first rdd starts with its first key as 0, the second as -1, the third as -2, and so on. I want to join the RDDs later so that they line up correctly for the n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "from for, X:  [(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "\n",
      "\n",
      "from nested for, RDDs[0]:\n",
      "[(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "1\n",
      "from for, X:  [(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n",
      "\n",
      "\n",
      "from nested for, RDDs[0]:\n",
      "[(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "from nested for, RDDs[1]:\n",
      "[(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n"
     ]
    }
   ],
   "source": [
    "RDDs = []\n",
    "for i in np.arange(N):\n",
    "    print(i)\n",
    "    X = sc.textFile(DATA_PATH)\\\n",
    "              .flatMap(lambda x: x.split(\" \"))\\\n",
    "              .zipWithIndex()\\\n",
    "              .mapValues(lambda x: x-i)\\\n",
    "              .map(lambda x: swap(x))\n",
    "    print(\"from for, X: \",X.take(10))\n",
    "    print(\"\\n\")\n",
    "    RDDs.append(X)\n",
    "    for i,rdd in enumerate(RDDs):\n",
    "        print(\"from nested for, RDDs[%s]:\"%i)\n",
    "        print(RDDs[i].take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the print statements, everything seems to be working so far. But here is where shit gets weird. When I ry to take from the RDDs outside of that for loop I get unexpected results. I would think that RDD[0] has the first RDD which we created, indexing starting at one. Then the second one starts at -1, and so on. But for whatever reason, that's not what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of for, RDDs[0]:  [(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n",
      "out of for, RDDs[1]:  [(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n"
     ]
    }
   ],
   "source": [
    "print(\"RDDs[0]: \",RDDs[0].take(10))\n",
    "print(\"RDDs[1]: \",RDDs[1].take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, it looks like RDDs[0] and RDDs[1] point to the same thing? But below, it's not so simle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDDs[0]:\n",
      "[(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "RDDs[1]:\n",
      "[(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n"
     ]
    }
   ],
   "source": [
    "for i,rdd in enumerate(RDDs):\n",
    "        print(\"RDDs[%s]:\"%i)\n",
    "        print(RDDs[i].take(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we enumerate the list, it behaves appropriately. Why? The below code mimics the bad behavior though, even though we're using the enumerator again. What the hell is going on here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "RDDs[i]: [(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "new X:  [(0, 'Copyright'), (1, 'laws'), (2, 'are'), (3, 'changing'), (4, 'all'), (5, 'over'), (6, 'the'), (7, 'world.'), (8, 'Be'), (9, 'sure')]\n",
      "i 1\n",
      "RDDs[i]: [(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n",
      "before join, X:  [(-1, 'Copyright'), (0, 'laws'), (1, 'are'), (2, 'changing'), (3, 'all'), (4, 'over'), (5, 'the'), (6, 'world.'), (7, 'Be'), (8, 'sure')]\n",
      "\n",
      "after join, X:  [(0, ('laws', 'laws')), (4, ('over', 'over')), (8, ('sure', 'sure')), (12, ('copyright', 'copyright')), (16, ('country', 'country')), (20, ('redistributing', 'redistributing')), (24, ('other', 'other')), (28, ('', '')), (32, ('be', 'be')), (36, ('seen', 'seen'))]\n",
      "\n",
      "new X:  [(0, ('laws', 'laws')), (4, ('over', 'over')), (8, ('sure', 'sure')), (12, ('copyright', 'copyright')), (16, ('country', 'country')), (20, ('redistributing', 'redistributing')), (24, ('other', 'other')), (28, ('', '')), (32, ('be', 'be')), (36, ('seen', 'seen'))]\n"
     ]
    }
   ],
   "source": [
    "for i,rdd in enumerate(RDDs):\n",
    "    print(\"i\",i)\n",
    "    print(\"RDDs[i]:\", RDDs[i].take(10))  \n",
    "    if i==0: \n",
    "        X = rdd\n",
    "    else:\n",
    "        print(\"before join, X: \",X.take(10))\n",
    "        print()\n",
    "        X = X.join(rdd)\n",
    "        print(\"after join, X: \",X.take(10))\n",
    "        print()\n",
    "    print(\"new X: \",X.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
